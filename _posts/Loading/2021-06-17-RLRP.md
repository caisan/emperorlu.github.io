---
title: 'paper: RLRP'
tags:
  - Load_Balancing
---

# Learning Replica Placement with RLRP in Distributed Storage Systems  

> **人类总会选择最安全、最中庸的道路前进，群星就会变成遥不可及的幻梦。— 小夫**

## Abstract

## Introduce

- （**副本放置**对分布式系统可靠性非常重要）

The disk structure of each Sub-tree is based on SStables like RocksDB. But RLRP abandons the design of index block in SStable, and uses efficient learned index to build a learned index block to improve the SStable read performance. The learned index block includes two modules: String Process and Learned Index. String Process is mainly responsible for efficiently converting strings into integer numbers for model training. For Learned Index, we use a two-layer linear model of RMI[26], which is sufficient to handle most workloads[26, 45]. Different from the traditional binary search, the learned index block directly predicts the block where it is located through the model, which is faster than the binary search. More importantly, the learned index block is much smaller than the traditional index block, and can be cached more in memory, which is more conducive to read performance. 

Replication remains a key technique to achieve desired data availability and reliability in many storage systems [2], [3], [4], [7], [8].
Its core concept is to automatically replicate data objects and distribute them to multiple devices.   

- （有很多副本放置算法，**存在问题**）

The ever-growing creation of, and demand for, massive amounts of data requires highly scalable storage solutions. The most flexible approach is to use a pool of storage devices  that can be expanded and scaled down as needed by adding new storage devices or removing older ones. This approach, however, necessitates a scalable solution for locating data items in such a dynamic environment, which has led to the proposal of several families of data distribution strategies.

- （**提出基于强化学习的副本放置算法**）



## Motivation

- （**问题抽象**）

Our research is based on an extension of the standard “balls into bins” model [Johnson and Kotz 1977][Mitzenmacher 1996]. Let f0; : : : ; M - 1g be the set of all identifiers for the balls and f0-(n-1) be the set of all identifiers for the bins. Suppose that the current number of balls in the system is m ≤ M and that the current number of bins in the system is n ≤ N. We will often assume for simplicity that the balls and bins are numbered in a consecutive way starting with 0, but any numbering that gives unique numbers to each ball and bin would work for our strategies.

<img src="..\..\photos\sec2_ceph.png" alt="sec2_ceph" style="zoom: 15%;" />

Suppose that bin i can store up to bi (copies of) balls. Then we define its relative capacity as ci = bi= Pn j=0 -1 bj. We require that, for every ball, k copies must be stored in different bins for some fixed k. In this case, a trivial upper bound for the number
of balls the system can store while preserving fairness and redundancy is Pn j=0 -1 bj=k, but it can be much less than that in certain cases. We term the k copies of a ball a redundancy group.

- （**目标**）

Placement schemes for storing redundant information can be compared based on the following criteria (see also [Brinkmann et al. 2002]):

1) Capacity Efficiency and Fairness. A scheme is called capacity efficient if it allows us to store a near-maximum number of data blocks. We will see in the following that the fairness property is closely related to capacity efficiency, where fairness describes the property that the number of balls and requests received by a bin are proportional to its capacity.

2) Time Efficiency. A scheme is called time efficient if it allows a fast computation of the position of any copy of a data block without the need to refer to centralized tables. Schemes often use smaller tables that are distributed to each node that must locate blocks. 

3) Compactness. We call a scheme compact if the amount of information the scheme requires to compute the position of any copy of a data block is small (in particular, it should only depend on n—the number of bins).

4) Adaptivity. We call a scheme adaptive if it only redistributes a near-minimum amount of copies when new storage is added in order to get back into a state of fairness.  

5) 对于真实系统中，要考虑各种异构环境和因素，要兼顾性能和均衡性

- （其他分布算法的问题）

**【测试1】**，突出各个算法的问题

table-based

hash-based

1）一致性hash

2）crush

3）。。

4）。。



- （**强化学习**）

Reinforcement Learning (SUTTON; BARTO, 1998) is an area of machine learning concerned with how artificial agents ought to take actions in a certain environment with with goal of maximizing some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines(e.g. game theory, control theory, etc). In the case of machine learning, the environment is typically formulated as a Markov Decision Process (MDP), as many reinforcement learning algorithms for this context utilize dynamic programming techniques. The main difference between reinforcement learning and the classical dynamic programming methods is that in RL do not assume knowledge of an exact mathematical model of the MDP. An advantage of RL algorithms is that they can target large MDPs where exact methods become impracticable.

<img src="../../photos/image-20210422193919743.png" alt="image-20210422193919743" style="zoom: 33%;" />![q_learning](..\..\photos\q_learning.png)

Q-learning、DQN...

<img src="..\..\photos\RL\DQN.png" alt="load" style="zoom: 25%;" />

- （挑战）

1）如何对问题进行建模，如何定义强化学习各要素？

2）如何处理迁移问题？

3）当节点数和数据量比较大的情况下，如何加速训练？

4）异构环境，如何兼顾性能和均衡性？

## Design

- （基本模型）

RLRP adopts a space-efficient parti-tioned store. The data are stored in different partition struc-tures (called Sub-trees) according to any standard, such askey range, secondary (delete) keys and so on. RLRPusesa map to manage the mapping. Each Sub-tree is an LSM-tree structure in a disk. The memory structure in TridentKVis based on Memtable and Immutable just like RocksDB.The difference is that when flushing to the disk, instead offlushing the entire Memtable directly, the KV pairs in theMemtable are stored in buffers through a well-designed Par-tition Scheduler, and then flushed separately. The PartitionScheduler includes data buffers for partitioning and a light-weight L0 index structure to speed up L0 layer lookup. UnlikeRocksDB’s traditional column family partitioning[5], all par-titions of RLRPshare one Memtable, which reducesmemory overhead.

<img src="..\..\photos\RL\RLRP.png" alt="RL" style="zoom: 18%;" />

- Environment

Our virtual nodes have the same concept of virtual nodes in Dynamo and partitions in OpenStack-Swift which is an abstract layer for managing all system data into smaller parts, i.e., a set of objects, as it is shown in the hash mapping layer of Figure 6. Each data object on the system is mapped to a virtual node through the consistent hash function mapping. A hash function applies the identification of a data object to calculate the modulo operation using the total number of virtual nodes, defining then which virtual node the object belongs to. The number of objects in every virtual node is balanced due to the hash function of the hash mapping layer that outputs hashed values uniformly distributed. The hash function responsible for mapping data objects to the virtual node is set up only once and remains the same during the entire system operation. At deployment, before system start-up, the system administrator sets the total number of virtual nodes to a large value and never changes it; otherwise, it would break the property of  the consistent hashing technique by creating the side-effect of huge data movements. 

A virtual node can be replicated multiple times on different storage nodes, for example, Virtual Node 2 is replicated to Storage Nodes 1 and 3 in Figure 6. A Replica Placement Scheme (RPS) is responsible for defining the mapping of virtual node replicas to storage nodes. It specifies the replication factor, which happens to be 2 in our example meaning that each virtual node has two copies in our storage system and the placement of every virtual node replica as shown in Figure 6. By modifying the replica placement scheme, the storage system can dynamically manage data through operations of replica creation, migration and deletion. In this work, the RPS is modified in order to achieve load balancing of Get operations.  

- Common Interface

  - node can be replicated

- Memory Pool

- RL Agent

  ​		<img src="..\..\photos\RL\RL_NN.png" alt="load" style="zoom: 25%;" />			<img src="C:\lukai1\桌面\商汤实习\Blog\emperorlu.github.io\photos\RL\Migration.png" alt="Migration" style="zoom: 25%;" />             

  - Placement Agent
  - Migration Agent
  
- （迁移模型）

The disk structure of each Sub-tree is based on SStables like RocksDB. But RLRP abandons the design of index block in SStable, and uses efficient learned index to build a learned index block to improve the SStable read performance. The learned index block includes two modules: String Process and Learned Index. String Process is mainly responsible for efficiently converting strings into integer numbers for model training. For Learned Index, we use a two-layer linear model of RMI[26], which is sufficient to handle most workloads[26, 45]. Different from the traditional binary search, the learned index block directly predicts the block where it is located through the model, which is faster than the binary search. More importantly, the learned index block is much smaller than the traditional index block, and can be cached more in memory, which is more conducive to read performance. 

As shown in the left of Figure 6, RLRP uses the high-performance SPDK interface to manage the NVMe SSDs, avoiding the system overhead caused by the Linux I/O path. In addition, RLRP adopts  asynchronous IO for read process and provides asynchronous interfaces for the upper and lower processes. Aynchronous IO makes it possible to reduce the synchronization control overhead caused by competing I/O resources, and to coordinate the optimization of front-end and background processing speed. Read process. As shown in Figure 6, the read process is as follows: the upper-level program calls the asynchronous interface to access TridentKV. RLRP firstly searches the Memtable, Immutable Memtable and Partition Scheduler in turn in the memory. If not found, RLRP finds in the corresponding Sub-tree according to the map and searchs the SStable files. For read files, firstly RLRP read the bloom filter to determine whether it exists. Then quickly locate its data block through the learned index block, load it into the memory and find target key. 

（训练优化）

The disk structure of ecach sub-tree is based on SStables like Rocksdb. But RPRL abandons the design of learned index in SStable and use efficient learned index to build a learned index block to improve the SStable read performance. The learned index block includes two modules: String process and Lerarned index Block. String PRocess is mainlu readsponsible for efficentne converting string into ineteger numbers for model training. For Learned Index, we use a two-layer linear model of RMI, which is sufficient to handle most workloads. Different form the tradition binary search, the learned index block directly predicts the block where it is located through the model, which is faster than the binary search. More importantly, the learned index block is much smaller than the traditional index block, and can be cached more in memory, which is more conducive to read performance. As shown in the left  of Figure 7, RLRP uses the high-performance SPDK interface to manage the NVMe SSDs, avoiding the system overhead caused by the Linux I/O path. In addition, RLRP adopts asynchronous IO for read process and provides asynchronous interfaces for the upper and lower processes. Asynchronous IO makes it possible to reduce the synchronization control overhead caused by competing IO resources, and to coordinate the optimization of front-end and backgroung processing speed. 

Read process. As shown in Figure 8, the read process is as follows: the upper-level program callls the asynchronous interface to access TridentKV. RLRP firstly searches the Memtable, Immutable Memtable and Partition Scheduler in turn in the memory. If not found, RLRP finds in the corresponding sub-tree according to the map and searches the Sstable files. Foer read files, firstly RLRP read the bloom filter to determine whether it exists. Then  quickly locate its data block throught the learned index block, load it into the memory and find target key. In the process of replica placement, the basic principle when placing a repliuca need to be followed. Under the premise of not violating the basic principle of replica placement, the system can maintain high availability while achieving the balance of replica placement distribution as much as possible. The replica placement rules defined in this paper are as follows:  

1) Different replicas for the same data block should be placed on different data nodes. We need to ensure that the availability of the replica is not affected. The default replica placement strategy considers the impact of the node failure or the rack failure on the overall system availability. If all replicas for a data block are placed on a node, once the node fails, all replica will be lost and unrecoverable. Therefore, we should avoid placing the replicas of the same data block on the same node. 

2) Data replicas should be placed on a node with high availability. A node with high availabity is the node with fewer failures and less load in the cluster system over a period.  After the nodes fails, the data block can obtain relicas from other nodes and take over the failed noed tasks in order to ensure uninterrupted service of the cluster system. If a replica is placed on a node with low availability, the replica tends to be unavailabile as the node fails which result in losing the meaning of the data replica. Therefore, the replica should be placed on a node with high acailability.

<img src="..\..\photos\RL\train_RL.png" alt="load" style="zoom: 25%;" />

(3) The data block replicas should be evenly placed throughout the cluster system. The global placement of the data replica determines the amount of overhead for the node to access the nearest replica of the data block. If the data block replicas are placed in a centralized manner rather than evenly placement in the cluster system, although the overhead of some nodes is small in accessing the nearest replica of the data block, most nodes have a high cost of accessing the nearest replica. Therefore, the data block replicas should be evenly placed throughout the cluster  ceph.  After the nodes fails, the data block can obtain replicas from other nodes and take over the failed nodes tasks in order to ensure uninterrupted service of the cluster system. If a replica is place on a node with low avaiab

- （异构场景）

  <img src="..\..\photos\RL\Attention.png" alt="Attention" style="zoom:18%;" />

​      The dynamic multi-objective optimized replica placement and migration strategies for SaaS applications in edge cloud are proposed to deal with the problems mentioned above. The multiobjective optimized replica placement problem is solved according to the fast non-dominated sorting genetic algorithm. With following the defined replica placement rule, multiple factors including the file unavailability, node load and network transmission cost are considered comprehensively. Then, the optimal replica placement target selection strategy can be obtained according to the spatial congestion degree. Finally, the consistency management of replicas is performed by constructing the reliability record table to ensure the availability of the data and the reliability of replica placement. Besides, the replica migration model for access hotspots is proposed in order to deal with the file access hotspots problem caused by burst requests. The method is mainly divided into three parts, including obtaining the load of the data node, the hot file selection strategy and the dynamic replica migration. The data nodes are divided into overload nodes, equalization nodes and low load nodes according to the load status threshold. The number of required replicas can be obtained according to the hotspot file selection. The pairing migration relationship from the source node to target node is obtained. The main contributions are shown as follows 

- In ceph

  <img src="..\..\photos\RL\RLRP-Ceph.png" alt="RL" style="zoom: 20%;" />







## Implementation  

- （In ceph）
- 

## Evaluation

- 测试平台：Cloudsim、COSBench、fio/rados benchmark

  https://github.com/intel-cloud/cosbench

- Ceph

- 真实数据

## Related Work





## 讨论

- **2021.7.6**
- 通用的数据分布的问题基本没什么研究的，问题不够新颖，应该聚焦于具体的未提出未发觉的问题上
- 投稿Transactions on Storage，A类期刊，七月底完成一版

1. **问题不明确**：背景中需要增加其他分布方案的问题？

   - 类似于 Random Slicing: Efficient and Scalable Data Placement for Large-scale Storage Systems  

   <img src="..\..\photos\RL\\image-20210707141805636.png" alt="image-20210707141805636" style="zoom:50%;" />

2. 使用RL的**动机不纯**？
   - 将分布问题建模，动态分布问题可以看作组合优化问题，RL在解决组合优化问题中发挥出色

3. 迁移方案太过简单，很多因素需要考虑？
4. 方案中增加公式补充？
5. 优化表述不清楚，要结合图详细解释？
6. 测试规模小，osd目前测试到80？至少要扩到100，1000：训练极其慢？
7. 异构考虑较为简单，但是很多动态的不用考虑，应该考虑异构中静态元素。动态元素应当负载均衡考虑？
8. 异构测试效果如何对比说明，需要增加别的方案的测试结果？
9. 测试太少，增加对比测试目标：一致性hash，table-based，crush等等
10. 增加真实系统，真实数据的对比测试
11. **测试补充**

- 增加其他分布算法的测试
  - consistent hash：
  - crush：
  - random slicing：
  - table-based：
- 1000 osd的模型训练
  - 放低要求，加速训练
- 封装模型到ceph，真实数据对比测试
  - 

