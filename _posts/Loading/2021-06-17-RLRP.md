---
title: 'paper: RLRP'
tags:
  - Load_Balancing
---

# Learning Replica Placement with RLRP

> **人类总会选择最安全、最中庸的道路前进，群星就会变成遥不可及的幻梦。— 小夫**

## Abstract

## Introduce

- （**副本放置**对分布式系统可靠性非常重要）

Replication remains a key technique to achieve desired data availability and reliability in many storage systems [2], [3], [4], [7], [8].
Its core concept is to automatically replicate data objects and distribute them to multiple devices.   

- （有很多副本放置算法，**存在问题**）

The ever-growing creation of, and demand for, massive amounts of data requires highly scalable storage solutions. The most flexible approach is to use a pool of storage devices  that can be expanded and scaled down as needed by adding new storage devices or removing older ones. This approach, however, necessitates a scalable solution for locating data items in such a dynamic environment, which has led to the proposal of several families of data distribution strategies.

- （**提出基于强化学习的副本放置算法**）



## Motivation

- （**问题抽象**）

Our research is based on an extension of the standard “balls into bins” model [Johnson and Kotz 1977][Mitzenmacher 1996]. Let f0; : : : ; M - 1g be the set of all identifiers for the balls and f0-(n-1) be the set of all identifiers for the bins. Suppose that the current number of balls in the system is m ≤ M and that the current number of bins in the system is n ≤ N. We will often assume for simplicity that the balls and bins are numbered in a consecutive way starting with 0, but any numbering that gives unique numbers to each ball and bin would work for our strategies.

<img src="..\..\photos\sec2_ceph.png" alt="sec2_ceph" style="zoom: 15%;" />

Suppose that bin i can store up to bi (copies of) balls. Then we define its relative capacity as ci = bi= Pn j=0 -1 bj. We require that, for every ball, k copies must be stored in different bins for some fixed k. In this case, a trivial upper bound for the number
of balls the system can store while preserving fairness and redundancy is Pn j=0 -1 bj=k, but it can be much less than that in certain cases. We term the k copies of a ball a redundancy group.

- （**目标**）

Placement schemes for storing redundant information can be compared based on the following criteria (see also [Brinkmann et al. 2002]):

1) Capacity Efficiency and Fairness. A scheme is called capacity efficient if it allows us to store a near-maximum number of data blocks. We will see in the following that the fairness property is closely related to capacity efficiency, where fairness describes the property that the number of balls and requests received by a bin are proportional to its capacity.

2) Time Efficiency. A scheme is called time efficient if it allows a fast computation of the position of any copy of a data block without the need to refer to centralized tables. Schemes often use smaller tables that are distributed to each node that must locate blocks.

3) Compactness. We call a scheme compact if the amount of information the scheme requires to compute the position of any copy of a data block is small (in particular, it should only depend on n—the number of bins).

4) Adaptivity. We call a scheme adaptive if it only redistributes a near-minimum amount of copies when new storage is added in order to get back into a state of fairness.  

5) 对于真实系统中，要考虑各种异构环境和因素，要兼顾性能和均衡性

- （其他分布算法的问题）

**【测试1】**，突出各个算法的问题

table-based

hash-based

1）一致性hash

2）crush

3）。。

4）。。



- （**强化学习**）

Reinforcement Learning (SUTTON; BARTO, 1998) is an area of machine learning concerned with how artificial agents ought to take actions in a certain environment with with goal of maximizing some notion of cumulative reward. The problem, due to its generality, is studied in many other disciplines(e.g. game theory, control theory, etc). In the case of machine learning, the environment is typically formulated as a Markov Decision Process (MDP), as many reinforcement learning algorithms for this context utilize dynamic programming techniques. The main difference between reinforcement learning and the classical dynamic programming methods is that in RL do not assume knowledge of an exact mathematical model of the MDP. An advantage of RL algorithms is that they can target large MDPs where exact methods become impracticable.

<img src="../../photos/image-20210422193919743.png" alt="image-20210422193919743" style="zoom: 33%;" />![q_learning](..\..\photos\q_learning.png)

Q-learning、DQN...

<img src="..\..\photos\RL\DQN.png" alt="load" style="zoom: 25%;" />

- （挑战）

1）如何对问题进行建模，如何定义强化学习各要素？

2）如何处理迁移问题？

3）当节点数和数据量比较大的情况下，如何加速训练？

4）异构环境，如何兼顾性能和均衡性？

## Design

- （基本模型）

RLRP adopts a space-efficient parti-tioned store. The data are stored in different partition struc-tures (called Sub-trees) according to any standard, such askey range, secondary (delete) keys and so on. RLRPusesa map to manage the mapping. Each Sub-tree is an LSM-tree structure in a disk. The memory structure in TridentKVis based on Memtable and Immutable just like RocksDB.The difference is that when flushing to the disk, instead offlushing the entire Memtable directly, the KV pairs in theMemtable are stored in buffers through a well-designed Par-tition Scheduler, and then flushed separately. The PartitionScheduler includes data buffers for partitioning and a light-weight L0 index structure to speed up L0 layer lookup. UnlikeRocksDB’s traditional column family partitioning[5], all par-titions of RLRPshare one Memtable, which reducesmemory overhead.

<img src="..\..\photos\RL\RLRP.png" alt="RL" style="zoom: 18%;" />

- Environment

Our virtual nodes have the same concept of virtual nodes in Dynamo and partitions in OpenStack-Swift which is an abstract layer for managing all system data into smaller parts, i.e., a set of objects, as it is shown in the hash mapping layer of Figure 6. Each data object on the system is mapped to a virtual node through the consistent hash function mapping. A hash function applies the identification of a data object to calculate the modulo operation using the total number of virtual nodes, defining then which virtual node the object belongs to. The number of objects in every virtual node is balanced due to the hash function of the hash mapping layer that outputs hashed values uniformly distributed. The hash function responsible for mapping data objects to the virtual node is set up only once and remains the same during the entire system operation. At deployment, before system start-up, the system administrator sets the total number of virtual nodes to a large value and never changes it; otherwise, it would break the property of  the consistent hashing technique by creating the side-effect of huge data movements. 

A virtual node can be replicated multiple times on different storage nodes, for example, Virtual Node 2 is replicated to Storage Nodes 1 and 3 in Figure 6. A Replica Placement Scheme (RPS) is responsible for defining the mapping of virtual node replicas to storage nodes. It specifies the replication factor, which happens to be 2 in our example meaning that each virtual node has two copies in our storage system and the placement of every virtual node replica as shown in Figure 6. By modifying the replica placement scheme, the storage system can dynamically manage data through operations of replica creation, migration and deletion. In this work, the RPS is modified in order to achieve load balancing of Get operations.  

- Common Interface

  - node can be replicated

- Memory Pool

- RL Agent

  <img src="..\..\photos\RL\RL_NN.png" alt="load" style="zoom: 25%;" />

  - Placement Agent
  - Migration Agent

The disk structure of each Sub-treeis based on SStables like RocksDB. But RLRPabandonsthe design of index block in SStable, and uses efficient learnedindex to build a learned index block to improve the SStableread performance. The learned index block includes two mod-ules: String Process and Learned Index. String Process ismainly responsible for efficiently converting strings into inte-ger numbers for model training. For Learned Index, we usea two-layer linear model of RMI[26], which is sufficient tohandle most workloads[26, 45].Different from the traditional binary search, the learnedindex block directly predicts the block where it is locatedthrough the model, which is faster than the binary search. More importantly, the learned index block is much smallerthan the traditional index block, and can be cached more inmemory, which is more conducive to read performance.

- （迁移模型）

<img src="C:\lukai1\桌面\商汤实习\Blog\emperorlu.github.io\photos\RL\Migration.png" alt="Migration" style="zoom: 25%;" />

As shown inthe left of Figure 6, RLRPuses the high-performanceSPDK interface to manage the NVMe SSDs, avoiding thesystem overhead caused by the Linux I/O path. In addition,RLRP adopts  asynchronous  IO  for  read  process  andprovides asynchronous interfaces for the upper and lowerprocesses. Aynchronous IO makes it possible to reduce thesynchronization control overhead caused by competing I/Oresources, and to coordinate the optimization of front-end andbackground processing speed.Read process.As shown in Figure 6, the read process isas follows: the upper-level program calls the asynchronousinterface to access TridentKV. RLRPfirstly searches theMemtable, Immutable Memtable and Partition Scheduler inturn in the memory. If not found, RLRPfinds in thecorresponding Sub-tree according to the map and searchs theSStable files. For read files, firstly RLRPread the bloomfilter to determine whether it exists. Then quickly locate itsdata block through the learned index block, load it into thememory and find target key 

- （训练优化）

  ​														<img src="..\..\photos\RL\train_RL.png" alt="load" style="zoom: 25%;" />         

In the process of replica placement, the basic principle when placing a replica need to be followed. Under the premise of
not violating the basic principle of replica placement, the system can maintain high availability while achieving the balance of
replica distribution as much as possible. The replica placement rules defined in this paper are as follows.

(1) Different replicas for the same data block should be placed on different data nodes. We need to ensure that the availability of the replica is not affected. The default replica placement strategy considers the impact of the node failure or the rack failure on the overall system availability. If all replicas for a data block are placed on a node, once the node fails, all replicas will be lost and unrecoverable. Therefore, we should avoid placing the replicas of the same data block on the same node.

(2) Data replicas should be placed on a node with high availability. A node with high availability is the node with fewer failures
and less load in a cluster system over a period. After the node fails, the data block can obtain reliable data replicas from other
nodes and take over the failed node tasks in order to ensure uninterrupted service of the cluster system. If a replica is placed
on a node with low availability, the replica tends to be unavailable as the node fails which result in losing the meaning of the data
replica. Therefore, the replicas should be placed on a node with high availability.

(3) The data block replicas should be evenly placed throughout the cluster system. The global placement of the data replica determines the amount of overhead for the node to access the nearest replica of the data block. If the data block replicas are placed in a centralized manner rather than evenly placement in the cluster system, although the overhead of some nodes is small in accessing the nearest replica of the data block, most nodes have a high cost of accessing the nearest replica. Therefore, the data block replicas should be evenly placed throughout the cluster sy  

- （异构场景）

  <img src="..\..\photos\RL\Attention.png" alt="Attention" style="zoom:18%;" />
  
  The dynamic multi-objective optimized replica placement and migration strategies for SaaS applications in edge cloud are proposed to deal with the problems mentioned above. The multiobjective optimized replica placement problem is solved according to the fast non-dominated sorting genetic algorithm. With following the defined replica placement rule, multiple factors including the file unavailability, node load and network transmission cost are considered comprehensively. Then, the optimal replica placement target selection strategy can be obtained according to the spatial congestion degree. Finally, the consistency management of replicas is performed by constructing the reliability record table to ensure the availability of the data and the reliability of replica placement. Besides, the replica migration model for access hotspots is proposed in order to deal with the file access hotspots problem caused by burst requests. The method is mainly divided into three parts, including obtaining the load of the data node, the hot file selection strategy and the dynamic replica migration. The data nodes are divided into overload nodes, equalization nodes and low load nodes according to the load status threshold. The number of required replicas can be obtained according to the hotspot file selection. The pairing migration relationship from the source node to target node is obtained. The main contributions are shown as follows  
  
- In ceph

  <img src="..\..\photos\RL\RLRP-Ceph.png" alt="RL" style="zoom: 20%;" />

## Implementation  

- （In ceph）

## Evaluation

- 测试平台：Cloudsim、COSBench、fio/rados benchmark

  https://github.com/intel-cloud/cosbench

- Ceph

- 真实数据

## Related Work
